---
apiVersion: v1
kind: ConfigMap
metadata:
  name: exporter-graphs-cm
data:
  # default setting
  ernie.json: |
    []
  akka-exporter.json: |
    [
      {"graphName":"Running Actors", "promQL":["akka_actor_running_actors{workload=\"$workloadId\"}"}],
      {"graphName":"Sent Messages", "promQL":["irate(akka_actor_sent_messages{workload=\"$workloadId\"}[1m])"}],
      {"graphName":"Processed Messages", "promQL":["irate(akka_actor_processed_messages{workload=\"$workloadId\"}[1m])"}],
      {"graphName":"Unhandled Messages", "promQL":["akka_actor_unhandled_message{workload=\"$workloadId\"}"}],
      {"graphName":"Actor Failures", "promQL":["akka_actor_actor_failure{workload=\"$workloadId\"}"}],
      {"graphName":"Dead Letters", "promQL":["akka_actor_dead_letter{workload=\"$workloadId\"}"}],
      {"graphName":"Mailbox Size", "promQL":["sum by (actor)(akka_actor_mailbox_size{workload=\"$workloadId\"})"]},
      {"graphName":"Processing Time", "promQL":["sum by (actor)(akka_actor_processing_time_ns{workload=\"$workloadId\"})"]},
      {"graphName":"Mailbox Time", "promQL":["sum by (actor)(akka_actor_mailbox_time_ns{workload=\"$workloadId\"})"]},
      {"graphName":"Stash Size", "promQL":["sum by (actor)(akka_actor_stash_size{workload=\"$workloadId\"})"]},
      {"graphName":"Processed Messages", "promQL":["sum by (actor)(irate(akka_actor_processed_messages{workload=\"$workloadId\"}[1m]))"]},
      {"graphName":"Running Actors", "promQL":["sum by (actor)(akka_actor_running_actors{workload=\"$workloadId\"})"]},
      {"graphName":"Sent Messages", "promQL":["sum by (actor)(irate(akka_actor_sent_messages{workload=\"$workloadId\"}[1m]))"]},
      {"graphName":"Processed Messages", "promQL":["sum by (actor)(irate(akka_actor_processed_messages{workload=\"$workloadId\"}[1m]))"]},
      {"graphName":"Unhandled Messages", "promQL":["sum by (actor)(akka_actor_unhandled_message{workload=\"$workloadId\"})"]},
      {"graphName":"Actor Failures", "promQL":["sum by (actor) (akka_actor_actor_failure{workload=\"$workloadId\"})"]},
      {"graphName":"Dead Letters", "promQL":["sum by (actor) (akka_actor_dead_letter{workload=\"$workloadId\"})"]},

      {"graphName":"Dispatcher Queue Time", "promQL":["sum by (actor) (akka_dispatcher_queue_time_ns{workload=\"$workloadId\"})"]},
      {"graphName":"Dispatcher Processing Time", "promQL":["sum by (actor) (akka_dispatcher_processing_time_ns{workload=\"$workloadId\"})"]},
      {"graphName":"Dispatcher Queue Size", "promQL":["sum by (actor) (akka_dispatcher_queue_size{workload=\"$workloadId\"})"]},
      {"graphName":"Dispatcher Processing", "promQL":["sum by (actor) (akka_dispatcher_processing{workload=\"$workloadId\"})"]},
      {"graphName":"Dispatcher Pool Size", "promQL":["sum by (actor) (akka_dispatcher_pool_size{workload=\"$workloadId\"})"]},
      {"graphName":"Dispatcher Active Threads", "promQL":["sum by (actor) (akka_dispatcher_active_threads{workload=\"$workloadId\"})"]},
      {"graphName":"Dispatcher Running Threads", "promQL":["sum by (actor) (akka_dispatcher_running_threads{workload=\"$workloadId\"})"]},
      {"graphName":"Dispatcher Parallelism", "promQL":["sum by (actor) (akka_dispatcher_parallelism{workload=\"$workloadId\"})"]},

      {"graphName":"Routed Messages", "promQL":["sum by (actor) (akka_router_router_routed_messages{workload=\"$workloadId\"})"]},
      {"graphName":"Router Processing Time", "promQL":["sum by (actor) (akka_router_router_processing_time_ns{workload=\"$workloadId\"})"]}
    ]
  akka-http-exporter.json: |
    [
      {"graphName":"Response Rate", "promQL":["sum by (request_path)(irate(akka_http_request_path_endpoint_responses{workload=\"$workloadId\"}[1m]))"]},
      {"graphName":"Response Time", "promQL":["max by (request_path)(akka_http_request_path_endpoint_response_time_ns{workload=\"$workloadId\"})"]}
    ]
  kafka-exporter.json: |
    [
        {"graphName":"Broker Messages in ", "promQL": ["irate(kafka_server_brokertopicmetrics_messagesin_total{workload=\"$workloadId\"}[1m])"]},
        {"graphName":"Bytes In", "promQL": ["irate(kafka_server_brokertopicmetrics_bytesin_total{workload=\"$workloadId\"}[1m])"]},
        {"graphName":"Bytes Out", "promQL": ["irate(kafka_server_brokertopicmetrics_bytesout_total{workload=\"$workloadId\"}[1m])"]},
        {"graphName":"Log Size Growth", "promQL": ["irate(kafka_log_size{workload=\"$workloadId\"}[1m])"]},
        {"graphName":"Produce Requests", "promQL": ["irate(kafka_server_brokertopicmetrics_totalproducerequests_total{workload=\"$workloadId\"}[1m])"]},
        {"graphName":"Fetch Consumer Requests", "promQL": ["irate(kafka_network_requestmetrics_requests_total{request="FetchConsumer",workload=\"$workloadId\"}[1m])"]},
        {"graphName":"Fetch Follower Requests", "promQL": ["irate(kafka_network_requestmetrics_requests_total{request="FetchFollower",workload=\"$workloadId\"}[1m])"]},
        {"graphName":"Leader Count", "promQL": ["kafka_server_replicamanager_leadercount{workload=\"$workloadId\"}"]},
        {"graphName":"Under Replicated Partitions", "promQL": ["kafka_server_replicamanager_underreplicatedpartitions{workload=\"$workloadId\"}"]},
        {"graphName":"Offline Partition Count", "promQL": ["kafka_controller_kafkacontroller_offlinepartitionscount{workload=\"$workloadId\"}"]},
        {"graphName":"Active Controller Count", "promQL": ["kafka_controller_kafkacontroller_activecontrollercount{workload=\"$workloadId\"}"]},
        {"graphName":"Leader Elections", "promQL": ["kafka_controller_controllerstats_leaderelectionrateandtimems{workload=\"$workloadId\"}"]},
        {"graphName":"Unclean Leader Elections", "promQL": ["kafka_controller_controllerstats_uncleanleaderelectionspersec{workload=\"$workloadId\"}"]},
        {"graphName":"Last Isr Shrink", "promQL": ["irate(kafka_server_replicamanager_isrshrinks_total{workload=\"$workloadId\"}[1m])"]},
        {"graphName":"Last Isr Expand", "promQL": ["irate(kafka_server_replicamanager_isrexpands_total{workload=\"$workloadId\"}[1m])"]},
        {"graphName":"JVM Memory Used", "promQL": ["sum by (statefulset_kubernetes_io_pod_name)(jvm_memory_bytes_used{kubernetes_namespace='kafka',workload=\"$workloadId\"})"]},
        {"graphName":"JVM GC Time Young Gen", "promQL": ["jvm_gc_collection_seconds_sum{gc='G1 Young Generation',workload=\"$workloadId\"}"]},
        {"graphName":"JVM GC Time Old Gen", "promQL": ["jvm_gc_collection_seconds_sum{gc='G1 Old Generation', workload=\"$workloadId\"}"]}
    ]
  zookeeper-exporter.json: |
    [
        {"graphName":"Average Latency", "promQL": ["avg(zk_avg_latency{workload=\"$workloadId\"})"]},
        {"graphName":"Synced Followers", "promQL": ["zk_synced_followers{workload=\"$workloadId\"}"]},
        {"graphName":"Open File Descriptors", "promQL": ["zk_open_file_descriptor_count{workload=\"$workloadId\"}"]},
        {"graphName":"Pending Syncs", "promQL": ["zk_pending_syncs{workload=\"$workloadId\"}"]},
        {"graphName":"Connections", "promQL": ["zk_num_alive_connections{workload=\"$workloadId\"}"]}
    ]
  cassandra-exporter.json: |
    [
        {"graphName":"Storage", "promQL": ["irate(cassandra_storage_load{workload=\"$workloadId\"}[1m])"]},
        {"graphName":"Reads", "promQL": ["irate(cassandra_clientrequest_latency{clientrequest='Read', workload=\"$workloadId\"}[1m])"]},
        {"graphName":"Writes", "promQL": ["irate(cassandra_clientrequest_latency{clientrequest='Write', workload=\"$workloadId\"}[1m])"]},
        {"graphName":"Read Latency", "promQL": ["irate(cassandra_clientrequest_totallatency{clientrequest='Read', workload=\"$workloadId\"}[1m])"]},
        {"graphName":"Write Latency", "promQL": ["irate(cassandra_clientrequest_totallatency{clientrequest='Write', workload=\"$workloadId\"}[1m])"}
    ]
  redis-exporter.json: |
    [
        {"graphName":"Redis Memory Used", "promQL":["redis_memory_used_bytes{workload=\"$workloadId\"}"]},
        {"graphName":"Commands Processed", "promQL":["irate(redis_commands_processed_total{workload=\"$workloadId\"}[1m])"]},
        {"graphName":"Keys Evicted", "promQL":["redis_evicted_keys_total{workload=\"$workloadId\"}"]},
        {"graphName":"Connections", "promQL":["redis_connected_clients{workload=\"$workloadId\"}"]}
    ]
  memcached-exporter.json: |
   [
      {"graphName":"Miss Ratio", "promQL":["memcached_commands_total{workload=\"$workloadId\", status=\"miss\"}/memcached_commands_total{workload=\"$workloadId\"}"]},
      {"graphName":"Evictions", "promQL":["irate(memcached_items_evicted_total{workload=\"$workloadId\"}[1m])"]},
      {"graphName":"Connections Current", "promQL":["memcached_current_connections{workload=\"$workloadId\"}"]},
      {"graphName":"Connections Total Rate", "promQL":["irate(memcached_connections_total{workload=\"$workloadId\"}[1m])"]},
      {"graphName":"Items Current", "promQL":["memcached_current_items{workload=\"$workloadId\"}"]},
      {"graphName":"Cache Free", "promQL":["memcached_current_bytes{workload=\"$workloadId\"}/memcached_limit_bytes{workload=\"$workloadId\"}"]},
      {"graphName":"Items Evicted", "promQL":["irate(memcached_items_evicted_total{workload=\"$workloadId\"}[1m])"]},
      {"graphName":"Items Reclaimed Rate", "promQL":["irate(memcached_items_reclaimed_total{workload=\"$workloadId\"}[1m])"]},
      {"graphName":"Total Commands Rate", "promQL":["sum (irate(memcached_commands_total{workload=\"$workloadId\"}[1m])) by (command)"]},
      {"graphName":"Read Bytes Rate", "promQL":["irate(memcached_read_bytes_total{workload=\"$workloadId\"}[1m])"]},
      {"graphName":"Written Bytes Rate", "promQL":["irate(memcached_written_bytes_total{workload=\"$workloadId\"}[1m])"]}
   ]
 jvm-exporter.json: |
  [
      {"graphName":"Heap", "promQL": [jvm_heap_committed{workload=\"$workloadId\"},
                                      jvm_heap_init{workload=\"$workloadId\"},
                                      jvm_heap_max{workload=\"$workloadId\"},
                                      jvm_heap_used{workload=\"$workloadId\"}]},
      {"graphName":"Non Heap", "promQL": [jvm_non_heap_committed{workload=\"$workloadId\"},
                                          jvm_non_heap_init{workload=\"$workloadId\"},
                                          jvm_non_heap_max{workload=\"$workloadId\"},
                                          jvm_non_heap_used{workload=\"$workloadId\"}]},
      {"graphName":"Total Heap", "promQL": [jvm_total_heap_committed{workload=\"$workloadId\"},
                                            jvm_total_heap_init{workload=\"$workloadId\"},
                                            jvm_total_heap_max{workload=\"$workloadId\"},
                                            jvm_total_heap_used{workload=\"$workloadId\"}]},
      {"graphName":"GC Count", "promQL": [jvm_PS_MarkSweep_count{workload=\"$workloadId\"},
                                          jvm_PS_Scavenge_count{workload=\"$workloadId\"}]},
      {"graphName":"GC Time", "promQL": [jvm_PS_MarkSweep_time{workload=\"$workloadId\"},
                                         jvm_PS_Scavenge_time{workload=\"$workloadId\"}]},
      {"graphName":"Class Loading", "promQL": [jvm_loaded{workload=\"$workloadId\"},
                                               jvm_unloaded{workload=\"$workloadId\"}]},
      {"graphName":"Memory Pools", "promQL": [jvm_pools_Code_Cache_usage{workload=\"$workloadId\"},
                                              jvm_pools_Compressed_Class_Space_usage{workload=\"$workloadId\"},
                                              jvm_pools_PS_Eden_Space_usage{workload=\"$workloadId\"}, jvm_pools_PS_Eden_Space_usage{workload=\"$workloadId\"},
                                              jvm_pools_PS_Old_Gen_usage{workload=\"$workloadId\"}, jvm_pools_PS_Eden_Space_usage{workload=\"$workloadId\"},
                                              jvm_pools_PS_Survivor_Space_usage{workload=\"$workloadId\"}, jvm_pools_PS_Eden_Space_usage{workload=\"$workloadId\"}
      ]},
  ]

# Job to add data-source to grafana
# 1. wait till grafana is up
# 2. add prometheus data source to grafana-server.
# Note: The IPaddress here is the address provided by minikube service list
# this IP address is not static, even for minikube
# Please note, browser should be able reach this IP-Address, it cannot be some internal IP address within kubernetes.
# like prometheus-server.lightbend will not work
#
---
apiVersion: v1
kind: ConfigMap
metadata:
  creationTimestamp: null
  name: grafana-datasource-cm
data:
  prometheus-datasource.json: |
      {
        "name": "Prometheus Lightbend",
        "type": "prometheus",
        "url": "http://192.168.99.100:30090",
        "access": "direct",
        "basicAuth": false
      }

---
apiVersion: batch/v1
kind: Job
metadata:
  name: add-grafana-datasource
spec:
  template:
    spec:
      initContainers:
      - name: wait-grafana
        image: radial/busyboxplus:curl
        imagePullPolicy: IfNotPresent
        command: ['sh', '-c', 'until curl -s http://grafana-server.lightbend:3000/login > /dev/null 2>&1 ; do echo waiting for grafana; sleep 2; done;']
      containers:
      - name: add-prometheus-datasource
        image: radial/busyboxplus:curl
        imagePullPolicy: IfNotPresent
        command: ["/bin/sh", "-c"]
        workingDir: /mnt/grafana/dashboards
        args:
          - >
            for file in *-datasource.json ; do
              if [ -e "$file" ] ; then
                echo "importing $file" &&
                curl --silent --fail --show-error \
                  --request POST http://admin:admin@grafana-server.lightbend:3000/api/datasources \
                  --header "Content-Type: application/json" \
                  --header "Accept: application/json" \
                  --data-binary "@$file" >> /tmp/datasource 2>&1  ;
                echo "" ;
              fi
            done ;

        volumeMounts:
        - name: grafana-datasource
          mountPath: /mnt/grafana/dashboards
      restartPolicy: Never
      volumes:
      - name: grafana-datasource
        configMap:
          name: grafana-datasource-cm

---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: grafana
    component: "server"
  name: grafana-server
spec:
  ports:
    - name: http
      port: 3000
      protocol: TCP
      targetPort: 3000
  selector:
    app: grafana
    component: "server"
  type: "ClusterIP"

---
apiVersion: v1
kind: Service
metadata:
  name: expose-grafana
spec:
  ports:
  - port: 3000
    protocol: TCP
    targetPort: 3000
    nodePort: 30030
  selector:
    app: grafana
    component: server
  type: NodePort

---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: grafana-server
  labels:
    app: grafana
    component: server
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: grafana
        component: server
    spec:
      containers:
      - image: lightbend-docker-registry.bintray.io/enterprise-suite/es-grafana:{{ .Values.esGrafanaVersion }}
        name: grafana-sever
        env:
          # The following env variables set up anonymous access to grafana with editor access.
          - name: GF_AUTH_ANONYMOUS_ENABLED
            value: "true"
          - name: GF_AUTH_ANONYMOUS_ORG_ROLE
            value: "Editor"
        ports:
          - containerPort: 3000
        readinessProbe:
          httpGet:
            path: /login
            port: 3000
        volumeMounts:
        - name: grafana-dashboards
          mountPath: /usr/share/grafana/public/conf
      volumes:
      - name: grafana-dashboards
        configMap:
          name: exporter-graphs-cm
